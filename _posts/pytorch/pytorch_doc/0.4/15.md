

# torch.Storage

* * *

`torch.Storage`是单个数据类型的连续的`一维数组`，每个`torch.Tensor`都具有相同数据类型的相应存储。

```py
class torch.FloatStorage
```

*   `byte()`：将Storage转为byte类型
*   `char()`:将Storage转为char类型
*   `clone()`:返回Storage的副本
*   `copy_()`
*   `cpu()`：如果尚未在CPU上，则返回Storage的CPU副本
*   `cuda(device=None, async=False)`：在CUDA内存中返回此对象的副本。如果该对象已经在CUDA内存中，并且在正确的设备上，则不会执行任何操作，并返回原始对象。 参数说明：

    1.  device (int) - 目标GPU的id。默认值是当前设备。
    2.  async (bool) -如果值为True，且源在锁定内存中，则副本相对于宿主是异步的。否则此参数不起效果。
*   `data_ptr()`： 返回一个时间戳
*   `double()`：将Storage转为double类型
*   `element_size()`：返回参数的size
*   `fill_()`
*   `float()`:将Storage转为float类型
*   `from_buffer()`
*   `half()`:将Storage转为half类型
*   `int()`:将Storage转为int类型
*   `is_cuda = False`
*   `is_pinned()`
*   `is_shared()`
*   `is_sparse = False`
*   `long()`:将Storage转为long类型
*   `new()`
*   `pin_memory()`：将存储复制到固定内存(如果尚未固定）。
*   `resize_()`
*   `share_memory_()`：这对于已经在共享内存和CUDA存储器中的存储器是无效的，不需要为了跨进程共享而移动。无法调整共享内存中的存储空间。返回：self
*   `short()`:将Storage转为short类型
*   `size()`：返回Storage转的大小
*   `tolist()`:返回一个包含Storage中元素的列表
*   `type(new_type=None, async=False)`：将此对象转为指定类型。如果已经是正确类型，不会执行复制操作，直接返回原对象。

参数说明：

1.  `new_type` (type或string) -需要转成的类型
2.  `async (bool)` -如果值为True，并且源处于固定内存中，目标位于GPU上，反之亦然，则相对于主机异步执行该副本。否则，参数没有效果。

具体使用教程请参考：[使用torch.Storage共享多个张量的相同存储以及将torch.Tensor转化为torch.Storage](https://ptorch.com/news/52.html)

### 译者署名

| 用户名 | 头像 | 职能 | 签名 |
| --- | --- | --- | --- |
| [Song](https://ptorch.com) | ![](img/2018033000352689884.jpeg) | 翻译 | 人生总要追求点什么 |

