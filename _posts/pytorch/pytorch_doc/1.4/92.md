# torch存储

> 原文： [https://pytorch.org/docs/stable/storage.html](https://pytorch.org/docs/stable/storage.html)

`torch.Storage`是单个数据类型的连续一维数组。

每个 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") 都有对应的相同数据类型的存储。

* * *

```
class torch.FloatStorage¶
```

* * *

```
bfloat16()¶
```

将此存储空间转换为 bfloat16 类型

* * *

```
bool()¶
```

将此存储转换为布尔型

* * *

```
byte()¶
```

将此存储空间转换为字节类型

* * *

```
char()¶
```

将此存储空间转换为 char 类型

* * *

```
clone()¶
```

返回此存储的副本

* * *

```
copy_()¶
```

* * *

```
cpu()¶
```

返回此存储的 CPU 副本(如果尚未在 CPU 上）

* * *

```
cuda(device=None, non_blocking=False, **kwargs)¶
```

返回此对象在 CUDA 内存中的副本。

如果此对象已经在 CUDA 内存中并且在正确的设备上，则不执行任何复制，并返回原始对象。

参数

*   **设备** (_python：int_ )–目标 GPU ID。 默认为当前设备。

*   **non_blocking**  (_bool_ )–如果`True`并且源位于固定内存中，则副本将相对于主机是异步的。 否则，该参数无效。

*   ****** –为兼容起见，可以包含键`async`来代替`non_blocking`参数。

* * *

```
data_ptr()¶
```

```
device¶
```

* * *

```
double()¶
```

将此存储空间转换为双精度类型

```
dtype¶
```

* * *

```
element_size()¶
```

* * *

```
fill_()¶
```

* * *

```
float()¶
```

将此存储转换为浮动类型

* * *

```
static from_buffer()¶
```

* * *

```
static from_file(filename, shared=False, size=0) → Storage¶
```

如果共享的&lt;cite&gt;为&lt;cite&gt;为&lt;/cite&gt;，则在所有进程之间共享内存。 所有更改都将写入文件。 如果&lt;cite&gt;共享的&lt;/cite&gt;为&lt;cite&gt;假&lt;/cite&gt;，则存储上的更改不会影响该文件。&lt;/cite&gt;

&lt;cite&gt;大小&lt;/cite&gt;是存储中元素的数量。 如果&lt;cite&gt;共享的&lt;/cite&gt;为&lt;cite&gt;假&lt;/cite&gt;，则文件必须至少包含 &lt;cite&gt;size * sizeof(Type）&lt;/cite&gt;个字节 (&lt;cite&gt;Type&lt;/cite&gt; 是存储类型 )。 如果&lt;cite&gt;共享的&lt;/cite&gt;为 &lt;cite&gt;True&lt;/cite&gt; ，则将根据需要创建文件。

Parameters

*   **文件名** (_str_ )–要映射的文件名

*   **共享的** (_bool_ )–是否共享内存

*   **大小** (_python：int_ )–存储中的元素数

* * *

```
half()¶
```

将此存储空间转换为一半类型

* * *

```
int()¶
```

将此存储空间转换为 int 类型

```
is_cuda = False¶
```

* * *

```
is_pinned()¶
```

* * *

```
is_shared()¶
```

```
is_sparse = False¶
```

* * *

```
long()¶
```

将此存储空间转换为长型

* * *

```
new()¶
```

* * *

```
pin_memory()¶
```

将存储复制到固定的内存(如果尚未固定）。

* * *

```
resize_()¶
```

* * *

```
share_memory_()¶
```

将存储移动到共享内存。

对于共享内存中已存在的存储和 CUDA 存储(对于跨进程共享无需移动的 CUDA 存储），此操作不起作用。 共享内存中的存储无法调整大小。

返回：自我

* * *

```
short()¶
```

将此存储空间转换为短型

* * *

```
size()¶
```

* * *

```
tolist()¶
```

返回包含此存储元素的列表

* * *

```
type(dtype=None, non_blocking=False, **kwargs)¶
```

如果未提供 &lt;cite&gt;dtype&lt;/cite&gt; ，则返回类型，否则将该对象强制转换为指定的类型。

如果它已经是正确的类型，则不执行任何复制，并返回原始对象。

Parameters

*   **dtype**  (_python：type_ _或_ _字符串_）–所需类型

*   **non_blocking**  (_bool_ )–如果`True`，并且源位于固定内存中，而目标位于 GPU 上，反之亦然，则相对于主机异步执行复制。 否则，该参数无效。

*   ****** –为兼容起见，可以包含键`async`来代替`non_blocking`参数。 不推荐使用`async` arg。