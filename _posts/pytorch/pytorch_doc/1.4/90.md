# torch随机

> 原文： [https://pytorch.org/docs/stable/random.html](https://pytorch.org/docs/stable/random.html)

* * *

```
torch.random.fork_rng(devices=None, enabled=True, _caller='fork_rng', _devices_kw='devices')¶
```

分叉 RNG，以便在您返回时将 RNG 重置为之前的状态。

参数

*   **设备**(可迭代的 CUDA ID 的_）–派生 RNG 的 CUDA 设备。 CPU RNG 状态始终为分叉。 默认情况下， [`fork_rng()`](#torch.random.fork_rng "torch.random.fork_rng") 可在所有设备上运行，但是如果您的计算机上有很多设备，则将发出警告，因为在这种情况下此功能运行非常缓慢。 如果您明确指定设备，该警告将被取消_

*   启用**的** (_bool_ )–如果`False`，则不分叉 RNG。 这是一个方便的参数，用于轻松禁用上下文管理器，而不必删除它并取消其下的 Python 代码的缩进。

* * *

```
torch.random.get_rng_state()¶
```

以 &lt;cite&gt;torch.ByteTensor&lt;/cite&gt; 的形式返回随机数生成器状态。

* * *

```
torch.random.initial_seed()¶
```

返回长为 Python &lt;cite&gt;long&lt;/cite&gt; 的用于生成随机数的初始种子。

* * *

```
torch.random.manual_seed(seed)¶
```

设置用于生成随机数的种子。 返回一个&lt;cite&gt;torch.生成器&lt;/cite&gt;对象。

Parameters

**种子** (_python：int_ )–所需的种子。

* * *

```
torch.random.seed()¶
```

将用于生成随机数的种子设置为不确定的随机数。 返回用于播种 RNG 的 64 位数字。

* * *

```
torch.random.set_rng_state(new_state)¶
```

设置随机数生成器状态。

Parameters

**new_state**  (_torch.ByteTensor_ )–所需状态

## 随机数发生器

* * *

```
torch.random.get_rng_state()
```

Returns the random number generator state as a &lt;cite&gt;torch.ByteTensor&lt;/cite&gt;.

* * *

```
torch.random.set_rng_state(new_state)
```

Sets the random number generator state.

Parameters

**new_state** (_torch.ByteTensor_) – The desired state

* * *

```
torch.random.manual_seed(seed)
```

Sets the seed for generating random numbers. Returns a &lt;cite&gt;torch.Generator&lt;/cite&gt; object.

Parameters

**seed** (_python:int_) – The desired seed.

* * *

```
torch.random.seed()
```

Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG.

* * *

```
torch.random.initial_seed()
```

Returns the initial seed for generating random numbers as a Python &lt;cite&gt;long&lt;/cite&gt;.

* * *

```
torch.random.fork_rng(devices=None, enabled=True, _caller='fork_rng', _devices_kw='devices')
```

Forks the RNG, so that when you return, the RNG is reset to the state that it was previously in.

Parameters

*   **devices** (_iterable of CUDA IDs_) – CUDA devices for which to fork the RNG. CPU RNG state is always forked. By default, [`fork_rng()`](#torch.random.fork_rng "torch.random.fork_rng") operates on all devices, but will emit a warning if your machine has a lot of devices, since this function will run very slowly in that case. If you explicitly specify devices, this warning will be suppressed

*   **enabled** (_bool_) – if `False`, the RNG is not forked. This is a convenience argument for easily disabling the context manager without having to delete it and unindent your Python code under it.