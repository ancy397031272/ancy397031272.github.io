# 张量属性

> 原文： [https://pytorch.org/docs/stable/tensor_attributes.html](https://pytorch.org/docs/stable/tensor_attributes.html)

每个`torch.Tensor`具有 [`torch.dtype`](#torch.torch.dtype "torch.torch.dtype") ， [`torch.device`](#torch.torch.device "torch.torch.device") 和 [`torch.layout`](#torch.torch.layout "torch.torch.layout") 。

## torch类型

* * *

```
class torch.dtype¶
```

[`torch.dtype`](#torch.torch.dtype "torch.torch.dtype") 是表示 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") 的数据类型的对象。 PyTorch 具有九种不同的数据类型：

| 

数据类型

 | 

dtype

 | 

张量类型

 |
| --- | --- | --- |
| 32 位浮点 | `torch.float32`或`torch.float` | `torch.*.FloatTensor` |
| 64 位浮点 | `torch.float64`或`torch.double` | `torch.*.DoubleTensor` |
| 16 位浮点 | `torch.float16`或`torch.half` | `torch.*.HalfTensor` |
| 8 位整数(无符号） | `torch.uint8` | `torch.*.ByteTensor` |
| 8 位整数(有符号） | `torch.int8` | `torch.*.CharTensor` |
| 16 位整数(有符号） | `torch.int16`或`torch.short` | `torch.*.ShortTensor` |
| 32 位整数(有符号） | `torch.int32`或`torch.int` | `torch.*.IntTensor` |
| 64 位整数(有符号） | `torch.int64`或`torch.long` | `torch.*.LongTensor` |
| 布尔型 | `torch.bool` | `torch.*.BoolTensor` |

要确定 [`torch.dtype`](#torch.torch.dtype "torch.torch.dtype") 是否为浮点数据类型，可以使用属性 [`is_floating_point`](torch.html#torch.is_floating_point "torch.is_floating_point") ，如果数据类型为浮点数据，则返回`True`。 类型。

当算术运算的输入 dtypes(&lt;cite&gt;加&lt;/cite&gt;，&lt;cite&gt;子&lt;/cite&gt;， &lt;cite&gt;div&lt;/cite&gt; ， &lt;cite&gt;mul&lt;/cite&gt; )不同时，我们通过寻找最小值来促进 满足以下规则的 dtype：

*   如果标量操作数的类型比张量操作数(浮动&gt;整数&gt;布尔值）具有更高的类别，则我们将其提升为具有足够大小的类型，以容纳该类别的所有标量操作数。

*   如果零维张量操作数的类别高于维操作数的类别，我们将提升为具有足够大小和类别的类型，以容纳该类别的所有零维张量操作数。

*   如果没有更高类别的零维操作数，我们将提升为具有足够大小和类别的类型以容纳所有尺寸的操作数。

浮点标量操作数的 dtype 为 &lt;cite&gt;torch.get_default_dtype(）&lt;/cite&gt;，整数非布尔标量操作数的 dtype 为 &lt;cite&gt;torch.int64&lt;/cite&gt; 。 与 numpy 不同，在确定操作数的最小 &lt;cite&gt;dtypes&lt;/cite&gt; 时，我们不检查值。 尚不支持量化和复杂类型。

促销示例：

```
>>> float_tensor = torch.ones(1, dtype=torch.float)
>>> double_tensor = torch.ones(1, dtype=torch.double)
>>> int_tensor = torch.ones(1, dtype=torch.int)
>>> long_tensor = torch.ones(1, dtype=torch.long)
>>> uint_tensor = torch.ones(1, dtype=torch.uint8)
>>> double_tensor = torch.ones(1, dtype=torch.double)
>>> bool_tensor = torch.ones(1, dtype=torch.bool)
# zero-dim tensors
>>> long_zerodim = torch.tensor(1, dtype=torch.long)
>>> int_zerodim = torch.tensor(1, dtype=torch.int)

>>> torch.add(5, 5).dtype
torch.int64
# 5 is an int64, but does not have higher category than int_tensor so is not considered.
>>> (int_tensor + 5).dtype
torch.int32
>>> (int_tensor + long_zerodim).dtype
torch.int32
>>> (long_tensor + int_tensor).dtype
torch.int64
>>> (bool_tensor + long_tensor).dtype
torch.int64
>>> (bool_tensor + uint_tensor).dtype
torch.uint8
>>> (float_tensor + double_tensor).dtype
torch.float64
>>> (bool_tensor + int_tensor).dtype
torch.int32
# Since long is a different kind than float, result dtype only needs to be large enough
# to hold the float.
>>> torch.add(long_tensor, float_tensor).dtype
torch.float32

```

```
When the output tensor of an arithmetic operation is specified, we allow casting to its dtype except that:
```

*   积分输出张量不能接受浮点张量。

*   布尔输出张量不能接受非布尔张量。

投放示例：

```
# allowed:
>>> float_tensor *= double_tensor
>>> float_tensor *= int_tensor
>>> float_tensor *= uint_tensor
>>> float_tensor *= bool_tensor
>>> float_tensor *= double_tensor
>>> int_tensor *= long_tensor
>>> int_tensor *= uint_tensor
>>> uint_tensor *= int_tensor

# disallowed (RuntimeError: result type can't be cast to the desired output type):
>>> int_tensor *= float_tensor
>>> bool_tensor *= int_tensor
>>> bool_tensor *= uint_tensor

```

## torch设备

* * *

```
class torch.device¶
```

[`torch.device`](#torch.torch.device "torch.torch.device") 是表示在其上或将要分配 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") 的设备的对象。

[`torch.device`](#torch.torch.device "torch.torch.device") 包含设备类型(`'cpu'`或`'cuda'`）和该设备类型的可选设备序号。 如果不存在设备序号，则即使调用 [`torch.cuda.set_device()`](cuda.html#torch.cuda.set_device "torch.cuda.set_device") ，该对象也始终代表设备类型的当前设备。 例如，用设备`'cuda'`构造的 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") 等效于`'cuda:X'`，其中 X 是 [`torch.cuda.current_device()`](cuda.html#torch.cuda.current_device "torch.cuda.current_device") 的结果。

可以通过 [`Tensor.device`](tensors.html#torch.Tensor.device "torch.Tensor.device") 属性访问 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") 的设备。

[`torch.device`](#torch.torch.device "torch.torch.device") 可以通过字符串或通过字符串和设备序号构造

通过字符串：

```
>>> torch.device('cuda:0')
device(type='cuda', index=0)

>>> torch.device('cpu')
device(type='cpu')

>>> torch.device('cuda')  # current cuda device
device(type='cuda')

```

通过字符串和设备序数：

```
>>> torch.device('cuda', 0)
device(type='cuda', index=0)

>>> torch.device('cpu', 0)
device(type='cpu', index=0)

```

注意

函数中的 [`torch.device`](#torch.torch.device "torch.torch.device") 参数通常可以用字符串替换。 这样可以快速编写代码原型。

```
>>> # Example of a function that takes in a torch.device
>>> cuda1 = torch.device('cuda:1')
>>> torch.randn((2,3), device=cuda1)

```

```
>>> # You can substitute the torch.device with a string
>>> torch.randn((2,3), device='cuda:1')

```

Note

出于遗留原因，可以通过单个设备序号(被视为 cuda 设备）构造设备。 这与 [`Tensor.get_device()`](tensors.html#torch.Tensor.get_device "torch.Tensor.get_device") 匹配，后者为 cuda 张量返回序数，而 cpu 张量不支持此序数。

```
>>> torch.device(1)
device(type='cuda', index=1)

```

Note

使用设备的方法通常会接受(正确格式化的）字符串或(旧式）整数设备序数，即以下所有等效方法：

```
>>> torch.randn((2,3), device=torch.device('cuda:1'))
>>> torch.randn((2,3), device='cuda:1')
>>> torch.randn((2,3), device=1)  # legacy

```

## torch布局

* * *

```
class torch.layout¶
```

[`torch.layout`](#torch.torch.layout "torch.torch.layout") 是表示 [`torch.Tensor`](tensors.html#torch.Tensor "torch.Tensor") 的内存布局的对象。 目前，我们支持`torch.strided`(密集张量），并为`torch.sparse_coo`(稀疏 COO 张量）提供实验性支持。

`torch.strided`代表密集的张量，是最常用的内存布局。 每个跨步张量都有一个关联的`torch.Storage`，它保存其数据。 这些张量提供了存储的多维[跨度](https://en.wikipedia.org/wiki/Stride_of_an_array)视图。 步幅是一个整数列表：第 k 个步幅表示在张量的第 k 个维度中从一个元素到下一个元素所需的内存跳转。 这个概念使得有可能高效地执行许多张量运算。

例：

```
>>> x = torch.Tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])
>>> x.stride()
(5, 1)

>>> x.t().stride()
(1, 5)

```

有关`torch.sparse_coo`张量的更多信息，请参见 [torch.sparse](sparse.html#sparse-docs) 。